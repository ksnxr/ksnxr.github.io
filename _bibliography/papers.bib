---
---


@article{yu_scalable_2023,
	title = {Scalable {Stochastic} {Gradient} {Riemannian} {Langevin} {Dynamics} in {Non}-{Diagonal} {Metrics}},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=dXAuvo6CGI},
	journal = {Transactions on Machine Learning Research},
	author = {Yu, Hanlin and Hartmann, Marcelo and Williams, Bernardo and Klami, Arto},
	year = {2023},
}

@inproceedings{yu_riemannian_2024,
	series = {Proceedings of {Machine} {Learning} {Research}},
	title = {Riemannian {Laplace} {Approximation} with the {Fisher} {Metric}},
	volume = {238},
	url = {https://proceedings.mlr.press/v238/yu24a.html},
	abstract = {Laplace’s method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments.},
	booktitle = {Proceedings of {The} 27th {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Yu, Hanlin and Hartmann, Marcelo and Williams Moreno Sanchez, Bernardo and Girolami, Mark and Klami, Arto},
	editor = {Dasgupta, Sanjoy and Mandt, Stephan and Li, Yingzhen},
	month = may,
	year = {2024},
	pages = {820--828},
}

@misc{yu_connecting_2025,
	title = {Connecting {Neural} {Models} {Latent} {Geometries} with {Relative} {Geodesic} {Representations}},
	url = {https://arxiv.org/abs/2506.01599},
	author = {Yu, Hanlin and Inal, Berfin and Arvanitidis, Georgios and Hauberg, Soren and Locatello, Francesco and Fumero, Marco},
	year = {2025},
	note = {accepted to NeurIPS 2025},
}

@inproceedings{yu_density_2025,
	title = {Density {Ratio} {Estimation} with {Conditional} {Probability} {Paths}},
	url = {https://openreview.net/forum?id=Gn2izAiYzZ},
	booktitle = {Forty-second {International} {Conference} on {Machine} {Learning}},
	author = {Yu, Hanlin and Klami, Arto and Hyvarinen, Aapo and Korba, Anna and Chehab, Omar},
	year = {2025},
}

@misc{yu_learning_2025,
	title = {Learning geometry and topology via multi-chart flows},
	url = {https://arxiv.org/abs/2505.24665},
	author = {Yu, Hanlin and Hauberg, Søren and Hartmann, Marcelo and Klami, Arto and Arvanitidis, Georgios},
	year = {2025},
	note = {\_eprint: 2505.24665},
}
